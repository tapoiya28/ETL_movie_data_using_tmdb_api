services:
  pgdatabase:
    image: postgres:17
    container_name: pgdatabase
    environment:
      POSTGRES_DB: movie_pipeline
      POSTGRES_USER: root
      POSTGRES_PASSWORD: root
    volumes:
      - ./.postgres/data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    networks:
      - movie-network
  afdatabase:
    image: postgres:17
    container_name: airflow_postgres
    environment:
      POSTGRES_DB: airflow_db
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
    volumes:
      - ./.afpostgres/data:/var/lib/postgresql/data
    networks:
      - movie-network

  airflow:
    image: apache/airflow:3.1.6
    container_name: airflow
    ports:
      - 8080:8080
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@afdatabase/airflow_db
    volumes:
      - ${AIRFLOW_PROJ_DIR:-.}/airflow/dags:/opt/airflow/dags
      - ${AIRFLOW_PROJ_DIR:-.}/ingest_api:/opt/airflow/ingest_api
      - ${AIRFLOW_PROJ_DIR:-.}/csv:/opt/airflow/csv
      - //var/run/docker.sock:/var/run/docker.sock
      # - ${AIRFLOW_PROJ_DIR:-.}/airflow/logs:/opt/airflow/logs
      # - ${AIRFLOW_PROJ_DIR:-.}/airflow/config:/opt/airflow/config
      # - ${AIRFLOW_PROJ_DIR:-.}/airflow/plugins:/opt/airflow/plugins
    depends_on:
      - afdatabase
    networks:
      - movie-network
    command: >
      bash -c " airflow db migrate && airflow standalone "

  dbt:
    container_name: dbt
    image: ghcr.io/dbt-labs/dbt-postgres:1.9.latest
    volumes:
      - ./dbt:/usr/app
      - ./dbt/profiles.yml:/root/.dbt/profiles.yml
    working_dir: /usr/app
    environment:
      DBT_PROFILES_DIR: "/root/.dbt"
    depends_on:
      - pgdatabase
    networks:
      - movie-network
    entrypoint: [ "/bin/bash", "/usr/app/entrypoint.sh" ]

networks:
  movie-network:
    driver: bridge
